---
title: "Untitled"
format: html
editor: visual
---

---
title: "<p style=\"color:black,text-align:center\">Supervised Machine Learning </p>"
author: 
  - name: <font color=#ff6600><b>Biometrics Unit</b></font> 
    affiliation: <font color=#ff6600><b>International Institute of Tropical Agriculture (IITA)</b></font>
format:
  html:
    toc-location: right
    toc: true
    toc-depth: 3
    toc_float:
    collapsed: True
    number_sections: false
    theme: readable
    highlight: monochrome
    fig_width: 5
    fig_height: 5
    fig_caption: true
    df_print: paged
    xaringan::moon_reader: null
    css: assets/rany_style.css
    lib_dir: libs
    nature:
      highlightStyle: github
---

# [**Supervised Learning**]{style="color: #234F1E;"}

In supervised learning, the algorithm is trained using a dataset where each input is matched with the corresponding output. This allows the model to learn how to predict the output for new, unseen inputs. This approach is commonly applied to tasks like classification, regression, and object detection.

In supervised learning, the machine learning algorithm learns from labeled data. Labeled data is data that has been tagged with a correct answer or classification. In supervised learning, the model learns from labeled examples (input-output pairs). It predicts outputs for new inputs. Classification and regression are common tasks.

![](images/Supervised-learning.png){width="50%"}

Source:geeks for geeks

**Examples**

Here are some examples of supervised learning:

-   **Regression**
-   **Classification**
-   **Object detection**
-   **Spam detection**
-   **Predictive analytics**
-   **Medical diagnosis**
-   **Speech recognition**
-   **Dimensional Reduction**

## [**Regression Use Case**]{style="color: #2C6D26;"}

Let's consider the `Honey.Wildflower.csv` dataset (13,016 records), this is a dataset in the public domain (Food science) with the following variables:

-   **CS (Color Score):** Represents the color score of the honey sample, ranging from 1.0 to 10.0.
-   **Density:** Represents the density of the honey sample in grams per cubic centimeter ranging from 1.21 to 1.86.
-   **WC (Water Content):** Represents the water content in the honey sample, ranging from 12.0% to 25.0%.
-   **pH:** Represents the pH level of the honey sample, ranging from 2.50 to 7.50.
-   **EC (Electrical Conductivity):** Represents the electrical conductivity of the honey sample in milli Siemens per centimeter.
-   **F (Fructose Level):** Represents the fructose level of the honey sample, ranging from 20 to 50.
-   **G (Glucose Level):** Represents the glucose level of the honey sample, ranging from 20 to 45.
-   **Pollen_analysis:** Represents the floral source of the honey sample.
-   **Purity:** Represents the purity of the honey sample, ranging from 0.01 to 1.00.
-   **Price:** The calculated price of the honey.

### **STEP 1 - Data Import**

The objective of this exercise is to develop a model that predicts the price of honey

Let's follow our 4 steps to address the objective:

-   STEP 1 - Data pre-processing
-   STEP 2 - Train the Model
-   STEP 3 - Evaluate the Model
-   STEP 4 - Test the Model

```{r message=FALSE}
library(tidyverse) #for data import & wrangling 
library(caret) #for model performance evaluation 
data <- read_csv("Honey.Wildflower.csv", na = c("", "NA")) 
data
```

### **STEP 2 - Data Pre-processing & EDA**

```{r }
summary(data)
```

The results above shows the summary statistics of each attributes in the dataset

```{r }
# Visualize the relationship among the attributes 
psych::pairs.panels(data |> select(-Pollen_analysis),                     gap = 0,                     
                 pch=21)
```

The plot shows the distribution of each feature and their relationship with other features. As shown, `purity` is perfectly correlated with the target feature - `price` we will exclude this attribute in our model because it distorts the regression results, making the linear regression coefficients of other features unreliable. Methods like regularization techniques (Lasso & Ridge Regression) which we are not covering in the course could be used to handle such case. We could have dropped those attributes with no strong correlation with `Price` individually, but they could have a combined effect with other attributes. Hence, it's worth keeping them for further analysis.

Also, looking at the distribution of each attribute, some are skewed while some are not. Let us scale the attributes to have them on uniform scale.

```{r }
# Feature scaling - exclude the categorical & the purity attribute 
data.sc <- scale(data |> select(-c(Purity, Pollen_analysis)),   center = TRUE,                             scale = TRUE) |>                   
       as.data.frame()  
head(data.sc)
```

### **STEP 3 - Data partition into training & testing datasets**

```{r }
# Let's partition the dataset to training & testing datasets using the 70 - 30 split ratio 
ind <- sample(c(TRUE, FALSE), nrow(data.sc),                replace = TRUE,                prob = c(0.7, 0.3))  

training <- data.sc[ind==TRUE,]  
testing <- data.sc[ind==FALSE,]  

# Cross check the dimension of the two datasets 

dim(training) 
dim(testing)
```

### **STEP 4 - Build the Model**

-   To build a simple linear regression model, let us consider the `pH` attribute of the dataset given that it has the highest correlation coefficient with the target feature.

```{r }
# Simple Linear Regression 
model.s <- lm(Price ~ pH, data=training) 
model.s
```

Before making use of the model for prediction, we need to assess the significance of the model using the function `summary()`

```{r }
# Model Summary 
summary(model.s)
```

The regression coefficient of `pH` in the model is -0.228, which imply that a unit increase in the `pH` level of honey will lead to a significant reduction in the average price of honey by 0.228. The R-squared result showed that about 5% of the variability in the price of honey can be explained by the `pH` of the honey. Also, the residual standard error is 0.972 which implies that the observed price deviate from the predicted value approximately by 0.972 unit on average using `pH` attribute alone.

```{r }
# Model Diagnostics 
par(mfrow=c(2,2)) 
plot(model.s)
```

### **STEP 5 - Model Performance Evaluation**

Let take a look at the Q-Q Residuals & Residual vs Fitted plots, as we can see the data points are not distributed randomly and they do not to align with the diagonal line which imply that the model do not fit the data well. This step is an important step as it helps evaluate how well the model will generalize to an independent dataset. Common metrics used to evaluate regression model performance are **R-squared (R2)**, **Root Mean Squared Error (RMSE)**, and **Mean Absolute Error (MAE)**. These metrics can simply be estimated using the testing dataset or re-sample the data multiple time before computing the metrics.

```{r }
#Cross Validation Method 1 
pred.s <- predict(model.s, testing) 

data.frame( R2 = R2(pred.s, testing$Price ),          RMSE = RMSE(pred.s, testing$Price ),             
        MAE = MAE(pred.s, testing$Price ))
```

```{r }
# Cross Validation Method 2 - define training control
set.seed(17) 
train.cv <- trainControl(method = "repeatedcv",                           number = 10, 

##number of resampling iteration (we do more than 10 in production)                         
repeats = 5)  ##number of repeated k-fold CV to compute                           
# Train the model 
model.cv.s <- train(Price ~ pH,                    
                    dat=training,   method = "lm",                  trControl = train.cv)  
# To get more options names(getModelInfo()) 

# Make prediction and compute the R2, RMSE and MAE 

pred.cv.s <- predict(model.cv.s, testing)

data.frame( R2 = R2(pred.cv.s, testing$Price ),             RMSE = RMSE(pred.cv.s, testing$Price ),             MAE = MAE(pred.cv.s, testing$Price ))
```

The correlation between the observed value of the honey price and the predicted value is 5.8% (NB: the higher the better) which is an indication that the model poorly fit the data. Similarly, the same conclusion can be made considering the higher values of the model's RMSE & MAE (NB: lower values are better). This implies that the attribute `pH` alone does not capture the variability in the `Price` of honey in the dataset. Therefore, let's consider fitting multiple linear regression.

## [**Classification Used Case**]{style="color: #2C6D26;"}

The `agricolae` package in R is primarily designed for agricultural research, providing tools for design, analysis, and multivariate analysis. However, it does not directly focus on classification in the traditional supervised machine learning sense (like you would find in packages such as `caret`, `randomForest`, or `e1071`).

Nevertheless, you can use R to perform classification with some basic functions. I can provide you a sample workflow for performing classification using a dataset typically found in agriculture. Here's a basic example using the `iris` dataset (which is not from `agricolae`, but it is a commonly used dataset for demonstrating classification).

### **STEP 1 - Data Import**

First, make sure to install the required packages (if you haven't already):

```{r, eval=FALSE, message=FALSE}
install.packages("agricolae", repos = "https://cran.r-project.org/") 
install.packages("caret") 
install.packages("randomForest", repos = "https://cran.r-project.org/")  
# Load required libraries 
library(agricolae) 
library(caret) # For easy data splitting and model training 
library(randomForest)
```

**Load and Inspect the Dataset**

Load the `iris` dataset from the `agricolae` package and inspect its structure.

```{r}
# Load the iris dataset 
data(iris)  
# Inspect the dataset   
head(iris)  
```

### **Step 2 - Data Preprocessing**

```{r}
# View the structure of the dataset 
str(iris)  
summary(iris)
```

### **Step 3 - Data partition into training and testing datasets**

Split the dataset into training (70%) and testing (30%)

```{r}
set.seed(123) # For reproducibility 
trainIndex <- createDataPartition(iris$Species, p = .7,                                    list = FALSE,                                    times = 1) 
irisTrain <- iris[trainIndex, ] 
irisTest <- iris[-trainIndex, ]
```

### **Step 4 - Build the model**

```{r}
# Fit a classification model using Random Forest 
model_rf <- train(Species ~ ., data = irisTrain, method = "rf")  
# Model summary 
print(model_rf) 
```

**Results Across Tuning Parameters:**

**mtry:** In Random Forest, 'mtry' refers to the number of features randomly selected at each split in the decision trees. The results presented include three values for mtry (2, 3, and 4).

For mtry = 2, the model achieved the highest accuracy of 0.9488 and a Kappa statistic of 0.9221.

For mtry = 3, the accuracy was slightly lower at 0.9469, with a Kappa of 0.9192.

For mtry = 4, the accuracy dropped to 0.9427, with a Kappa of 0.9129.

Optimal mtry Selected: The model selected for final use is mtry = 2, which had the highest accuracy. This indicates that selecting two features for each decision tree split was the most effective in classifying the Iris species in this scenario. Interpretation of Performance Metrics:

**Accuracy:** An accuracy of around 94.9% suggests that the model correctly classifies about 94.9% of the instances in a typical scenario. This is quite high, especially for a classification problem with three classes.

**Kappa Statistic:** The Kappa statistic is a measure of agreement between the predicted and observed classifications. A Kappa value above 0.9 (as seen here) indicates almost perfect agreement, suggesting that the model's predictions are very reliable. Conclusion and Further Considerations: Given the high accuracy and Kappa scores, the Random Forest model seems to perform exceptionally well on this dataset.

### **Step 5 - Evaluate Model Parameter**

```{r}
# Make predictions on the test set 
predictions <- predict(model_rf, irisTest)  
# Confusion matrix to evaluate the model 
confusion_matrix <- table(irisTest$Species, predictions)

print(confusion_matrix)  
```

**Accuracy calculation**

```{r}
# Calculate accuracy   
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)  
print(paste("Accuracy:", round(accuracy, 4)))
```

**Feature Checking**

```{r, eval=FALSE, message=FALSE}
# Example of fitting a random forest model library(randomForest) 
rf_model <- randomForest(Species ~ ., data = iris)  
# Check the class of the model object 
class(rf_model) 
```

### Explanation:

1.  **Loading Libraries**: We load the `agricolae` (for agricultural data analysis) and `caret` (for classification and other machine learning tasks) libraries.

2.  **Dataset**: We use `iris`, a built-in dataset in R which contains information about different species of iris flowers based on sepal and petal dimensions.

3.  **Data Splitting**: The dataset is split into training and test sets to evaluate the performance of our model.

4.  **Model Training**: We train a Random Forest classifier on the training dataset. The `Species` column is our target variable, and the rest are features.

5.  **Predictions**: We use our trained model to make predictions on the test dataset.

6.  **Confusion Matrix**: Finally, we evaluate our model's performance using a confusion matrix, which shows how many instances were correctly predicted by the model.
