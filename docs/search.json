[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "UNLOCKING INSIGHTS: End-To-End Machine Learning(Supervised Machine Learning)",
    "section": "",
    "text": "Introduction to Machine Learning (ML)\nArtificial intelligence (AI) is a technology that equips machines with the ability to simulate human behaviour, specifically cognitive processes.\nMachine learning (ML) is a branch of AI that uses data and algorithms to learn in the same way humans do, gradually improving its accuracy. Machine learning algorithms use historical data as input to predict new output values.\n\nImage credit: GeoPard Agriculture\n\n\nML/AI Use Case in Agriculture (ML)\n\nAkilimo (https://akilimo.org/) combines ML with state-of-the-art crop models, geospatial statistics, and economic optimization algorithms to provide tailored recommendations that maximize net returns on investments within a user-defined budget.\n\nNuruAI (https://plantvillage.psu.edu/)) by IITA and Pennsylvania State University (USA) employs AI with ML to recognize symptoms of cassava brown streak disease, cassava mosaic disease, cassava green mite damage, and the healthy condition from images of cassava leaves.\n\nRiceAdvice (https://riceadvice.info) a smartphone app developed by the Africa Rice Center (AfricaRice), employs ML as part of its modeling framework. It provides field-specific management guidelines for rice production systems in Africa. The guidelines are generated based on farmers’ answers to multiple-choice questions about crop management practices and market conditions.\n\n\nIntroduction to Machine Learning (ML)\n\nSource: https://xkcd.com/1838/\n\nSupervised Learning: the goal is to learn a mapping from inputs to outputs, allowing the model to make predictions on new, unseen data. Common algorithms include linear regression, logistic regression, decision trees, support vector machines, random forest, etc.\n\n\nML: Key Considerations\nWhen working with machine learning, several key considerations should be taken into account to ensure quality model.\nData Quality: The quality of the data used for training is crucial because the success of a machine learning model heavily depends on it. This includes ensuring that the data is accurate, complete, and representative of the problem domain.\nSample Size: To have reliable model for prediction, the sample size has to be sufficiently large.\nFeature Engineering: This is the process of creating and transforming variables (features) from raw data to enhance the predictive power of ML models. These features can be numerical, categorical, etc. Knowing the data type and the unit of measurement of each feature is very important in performing feature engineering.\nFeature Selection: Identifying the right features (input variables) that contribute to the model’s performance is important. Irrelevant or redundant features can lead to overfitting and reduced model accuracy. Model Selection: Choosing the appropriate algorithm or model architecture based on the problem type (classification, regression, clustering, etc.) and the nature of the data is vital. Different models have different strengths and weaknesses.\nOverfitting and Underfitting: Balancing the model’s complexity is essential. Overfitting occurs when a model learns the training data too well, including noise, while underfitting happens when a model is too simple to capture the underlying patterns.\nHyperparameter Tuning: Many machine learning models have hyperparameters that need to be set before training. Tuning these parameters can significantly impact model performance and often requires techniques like grid search or random search.\nEvaluation Metrics: Selecting appropriate metrics to evaluate model performance is crucial. Common metrics include accuracy, precision, recall, F1-score, and area under the ROC curve (AUC-ROC) for the classification task, R-squared, RMSE, and MAE for the regression task.\nComputing Power: This is very important because not machines (laptop or desktop) have the power to handle certain ML task. When the data is large, which is usually the case in a typical ML task, machines with high processing power are recommended.\n\n\nSteps in Machine Learning\nSTEP 0 - Define the Problem and Collect/Gather the data that will be used to train the model\nSTEP 1 - Data pre-processing: * Clean the dataset to handle missing values, incorrect data, and remove duplicates.\n\nPerform exploratory data analysis (EDA) to understand the patterns, trends, and relationships within the data\nDivide the data into training and test sets Data transformation and normalization (training and test sets) to make it suitable for modeling.\n\nSTEP 2 - Train the Model: * Choose an ML model appropriate with the data (the target)\n\nCross-validation: Divide the training dataset into “k” subsets or “folds”. The model training and validation process is repeated “k” times, with each of the k folds used exactly once as the validation data, and the remaining k-1 folds used as training data\nTune the model (some ML): based on the performance metrics, adjust the model parameters. Hyperparameter tuning can be done manually or through automated methods like grid search or random search.\n\n\n\nIntroduction to Tidymodels (ML)\n\nhttps://www.tidymodels.org/\n\n\n\nData\nTo dive into the tidymodels proper, let us look at the data. Let’s consider the Honey dataset (247,903 records). This is a dataset in the public domain (Kaggle)\nThe Objective here is to predict the variable purity of honey using the features described below.\n\nPurity: Represents the purity of the honey sample, ranging from 0.01 to 1.00.\nCS (Color Score): Represents the color score of the honey sample, ranging from 1.0 to 10.0.\nDensity: Represents the density of the honey sample in grams per cubic centimeter at 25?C, ranging from 1.21 to 1.86.\nWC (Water Content): Represents the water content in the honey sample, ranging from 12.0% to 25.0%.\npH: Represents the pH level of the honey sample, ranging from 2.50 to 7.50.\nEC (Electrical Conductivity): Represents the electrical conductivity of the honey sample in milliSiemens per centimeter.\nF (Fructose Level): Represents the fructose level of the honey sample, ranging from 20 to 50.\nG (Glucose Level): Represents the glucose level of the honey sample, ranging from 20 to 45.\nPollen_analysis: Represents the floral source of the honey sample.\nPrice: The calculated price of the honey.\n\n\n\nClassification Task (ML)\nIn the regression task the response variable is quantitative. However, in several instances, the response variable is qualitative i.e. plant health status - healthy or not healthy, or disease severity status - mild, moderate, and severe, etc. Qualitative variables are referred to as categorical variables. The goal of classification is to predict the probability that an instance belongs to a particular class or not. However, the predictors can either be quantitative or qualitative variables.\nIn this part we go through the same procedure as the regression task. The major differences are the the specification of mode in the recipe function and the evaluation metrics. We are still going to use the random forest algorithm since it is both a classification and regression task.\nLet’s use the apple.csv dataset with 4,000 observations. This dataset contains information about various attributes of a set of fruits, providing insights into their characteristics.\nThe dataset includes the following key features:\n\nA_id: Unique identifier for each fruit\nSize: Size of the fruit\nWeight: Weight of the fruit\nSweetness: Degree of sweetness of the fruit\nCrunchiness: Texture indicating the crunchiness of the fruit\nJuiciness: Level of juiciness of the fruit\nRipeness: Stage of ripeness of the fruit\nAcidity: Acidity level of the fruit\nQuality: Overall quality of the fruit\n\nThe objective of this exercise is to build a model to predict the quality rating of the apple fruits based on their features."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]